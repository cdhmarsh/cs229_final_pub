{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains the code to run the baseline experiments.\n",
    "\n",
    "More specifically, we are investigating the performance of basic models on the CIFAR-10 and CIFAR-10H datasets. The tasks for these datasets are multi-class classification.\n",
    "\n",
    "The basic models include:\n",
    "    * ResNet-50\n",
    "    * VGG-16\n",
    "    * Logistic Regression\n",
    "    * Random Forest\n",
    "    * XGBoost\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset and return train, validation, and test DataLoaders\n",
    "def load_cifar10() -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ConvertImageDtype(torch.float32),\n",
    "        ]\n",
    "    )\n",
    "    full_dataset = datasets.CIFAR10(root=\"../data/cifar-10\", train=True, download=True, transform=transform)\n",
    "    # we use the test dataset for training, similar to the CIFAR-10H experiment\n",
    "    train_dataset = datasets.CIFAR10(root=\"../data/cifar-10\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # This dataset will be used for testing and validation.\n",
    "    #   30% of the data will be used for validation, and 70% for testing.\n",
    "    test_size = int(0.7 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - test_size\n",
    "    test_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [test_size, val_size], generator=torch.Generator().manual_seed(229)\n",
    "    )\n",
    "\n",
    "    return train_dataset, test_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_data(cifar10_train_dataset, cifar10_test_dataset):\n",
    "    # Prepare data for ML models\n",
    "    X_cifar10 = np.array([img.numpy().flatten() for img, _ in cifar10_train_dataset])\n",
    "    y_cifar10 = np.array([label for _, label in cifar10_train_dataset])\n",
    "\n",
    "    X_cifar10_test = np.array([img.numpy().flatten() for img, _ in cifar10_test_dataset])\n",
    "    y_cifar10_test = np.array([label for _, label in cifar10_test_dataset])\n",
    "\n",
    "    # Scale the data for ML models\n",
    "    scaler = StandardScaler()\n",
    "    X_cifar10_scaled = scaler.fit_transform(X_cifar10)\n",
    "    X_cifar10_scaled_test = scaler.transform(X_cifar10_test)\n",
    "\n",
    "    return X_cifar10_scaled, y_cifar10, X_cifar10_scaled_test, y_cifar10_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR-10 dataset loaded with 10000 training, 35000 test, and 15000 validation samples\n"
     ]
    }
   ],
   "source": [
    "cifar10_train_dataset, cifar10_test_dataset, cifar10_val_dataset = load_cifar10() \n",
    "cifar10_train_loader = DataLoader(cifar10_train_dataset, batch_size=128, shuffle=True)\n",
    "cifar10_test_loader = DataLoader(cifar10_test_dataset, batch_size=128, shuffle=False)\n",
    "cifar10_val_loader = DataLoader(cifar10_val_dataset, batch_size=128, shuffle=False)\n",
    "print(\n",
    "    f\"CIFAR-10 dataset loaded with {len(cifar10_train_dataset)} training, {len(cifar10_test_dataset)} test, and {len(cifar10_val_dataset)} validation samples\"\n",
    ")\n",
    "X_cifar10, y_cifar10, X_cifar10_test, y_cifar10_test = get_ml_data(cifar10_train_dataset, cifar10_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Training is done on the CIFAR-10 test set. Evaluation is done on the CIFAR-10 train set, which we use as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    num_epochs: int,\n",
    ") -> nn.Module:\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                if len(labels.shape) > 1:  # For soft labels\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    _, labels = torch.max(labels, 1)\n",
    "                else:  # For hard labels\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Save model if validation accuracy improves\n",
    "        if accuracy > best_val_acc:\n",
    "            best_val_acc = accuracy\n",
    "            torch.save(model.state_dict(), f\"models/{model.__class__.__name__}_cifar10.pth\")\n",
    "            print(f\"Saved model with improved validation accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(\n",
    "    model, cifar10_train_loader: DataLoader, cifar10_val_loader: DataLoader, num_epochs: int = 20, lr: float = 0.001\n",
    ") -> list:\n",
    "    print(f\"\\nTraining {model.__class__.__name__} on CIFAR-10...\")\n",
    "\n",
    "    # Adjust the final layer for CIFAR-10\n",
    "    if isinstance(model, models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 10)\n",
    "    elif isinstance(model, models.VGG):\n",
    "        num_ftrs = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=cifar10_train_loader,\n",
    "        val_loader=cifar10_val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "    )\n",
    "\n",
    "def evaluate_nn_model(model, cifar10_test_loader):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f\"models/{model.__class__.__name__}_cifar10.pth\", weights_only=True)\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        for images, labels in cifar10_test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{model.__class__.__name__} Accuracy on CIFAR-10 test set: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet on CIFAR-10...\n",
      "Using device: mps\n",
      "Epoch [1/20] Train Loss: 1.3078, Validation Loss: 1.3234, Accuracy: 53.88%\n",
      "Saved model with improved validation accuracy: 53.88%\n",
      "Epoch [2/20] Train Loss: 0.8497, Validation Loss: 1.0143, Accuracy: 66.02%\n",
      "Saved model with improved validation accuracy: 66.02%\n",
      "Epoch [3/20] Train Loss: 0.6114, Validation Loss: 0.8822, Accuracy: 71.39%\n",
      "Saved model with improved validation accuracy: 71.39%\n",
      "Epoch [4/20] Train Loss: 0.4668, Validation Loss: 0.9592, Accuracy: 70.69%\n",
      "Epoch [5/20] Train Loss: 0.3578, Validation Loss: 1.1160, Accuracy: 68.58%\n",
      "Epoch [6/20] Train Loss: 0.2868, Validation Loss: 1.4007, Accuracy: 65.35%\n",
      "Epoch [7/20] Train Loss: 0.2403, Validation Loss: 1.2300, Accuracy: 67.98%\n",
      "Epoch [8/20] Train Loss: 0.2920, Validation Loss: 1.2564, Accuracy: 67.11%\n",
      "Epoch [9/20] Train Loss: 0.2421, Validation Loss: 1.0697, Accuracy: 71.74%\n",
      "Saved model with improved validation accuracy: 71.74%\n",
      "Epoch [10/20] Train Loss: 0.1905, Validation Loss: 1.2155, Accuracy: 70.76%\n",
      "Epoch [11/20] Train Loss: 0.2191, Validation Loss: 1.0711, Accuracy: 72.41%\n",
      "Saved model with improved validation accuracy: 72.41%\n",
      "Epoch [12/20] Train Loss: 0.1509, Validation Loss: 1.1953, Accuracy: 71.21%\n",
      "Epoch [13/20] Train Loss: 0.0907, Validation Loss: 1.0887, Accuracy: 74.34%\n",
      "Saved model with improved validation accuracy: 74.34%\n",
      "Epoch [14/20] Train Loss: 0.0456, Validation Loss: 1.1695, Accuracy: 74.33%\n",
      "Epoch [15/20] Train Loss: 0.0587, Validation Loss: 1.3439, Accuracy: 71.69%\n",
      "Epoch [16/20] Train Loss: 0.1250, Validation Loss: 1.1617, Accuracy: 72.48%\n",
      "Epoch [17/20] Train Loss: 0.0395, Validation Loss: 1.1790, Accuracy: 74.55%\n",
      "Saved model with improved validation accuracy: 74.55%\n",
      "Epoch [18/20] Train Loss: 0.0939, Validation Loss: 1.1213, Accuracy: 74.23%\n",
      "Epoch [19/20] Train Loss: 0.0308, Validation Loss: 1.2362, Accuracy: 74.15%\n",
      "Epoch [20/20] Train Loss: 0.0528, Validation Loss: 1.3297, Accuracy: 72.78%\n",
      "ResNet Accuracy on CIFAR-10 test set: 74.77%\n"
     ]
    }
   ],
   "source": [
    "resnet_model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "train_nn_model(resnet_model, cifar10_train_loader, cifar10_val_loader, lr=0.01)\n",
    "evaluate_nn_model(resnet_model, cifar10_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training VGG on CIFAR-10...\n",
      "Using device: mps\n",
      "Epoch [1/20] Train Loss: 2.3457, Validation Loss: 2.3116, Accuracy: 9.88%\n",
      "Saved model with improved validation accuracy: 9.88%\n",
      "Epoch [2/20] Train Loss: 2.3088, Validation Loss: 2.3043, Accuracy: 9.88%\n",
      "Epoch [3/20] Train Loss: 2.3057, Validation Loss: 2.3064, Accuracy: 10.25%\n",
      "Saved model with improved validation accuracy: 10.25%\n",
      "Epoch [4/20] Train Loss: 2.3073, Validation Loss: 2.3053, Accuracy: 10.07%\n",
      "Epoch [5/20] Train Loss: 2.3053, Validation Loss: 2.3074, Accuracy: 9.83%\n",
      "Epoch [6/20] Train Loss: 2.3052, Validation Loss: 2.3047, Accuracy: 9.93%\n",
      "Epoch [7/20] Train Loss: 2.3058, Validation Loss: 2.3040, Accuracy: 9.93%\n",
      "Epoch [8/20] Train Loss: 2.3045, Validation Loss: 2.3040, Accuracy: 9.65%\n",
      "Epoch [9/20] Train Loss: 2.3047, Validation Loss: 2.3031, Accuracy: 9.93%\n",
      "Epoch [10/20] Train Loss: 2.3050, Validation Loss: 2.3028, Accuracy: 10.15%\n",
      "Epoch [11/20] Train Loss: 2.3038, Validation Loss: 2.3027, Accuracy: 10.15%\n",
      "Epoch [12/20] Train Loss: 2.3039, Validation Loss: 2.3030, Accuracy: 10.15%\n",
      "Epoch [13/20] Train Loss: 2.3051, Validation Loss: 2.3040, Accuracy: 10.27%\n",
      "Saved model with improved validation accuracy: 10.27%\n",
      "Epoch [14/20] Train Loss: 2.3042, Validation Loss: 2.3030, Accuracy: 10.07%\n",
      "Epoch [15/20] Train Loss: 2.3042, Validation Loss: 2.3032, Accuracy: 9.93%\n",
      "Epoch [16/20] Train Loss: 2.3037, Validation Loss: 2.3031, Accuracy: 10.27%\n",
      "Epoch [17/20] Train Loss: 2.3044, Validation Loss: 2.3035, Accuracy: 9.95%\n",
      "Epoch [18/20] Train Loss: 2.3043, Validation Loss: 2.3032, Accuracy: 10.07%\n",
      "Epoch [19/20] Train Loss: 2.3041, Validation Loss: 2.3029, Accuracy: 9.95%\n",
      "Epoch [20/20] Train Loss: 2.3034, Validation Loss: 2.3031, Accuracy: 9.88%\n",
      "VGG Accuracy on CIFAR-10 test set: 9.88%\n"
     ]
    }
   ],
   "source": [
    "vgg_model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "train_nn_model(vgg_model, cifar10_train_loader, cifar10_val_loader, lr=0.01)\n",
    "evaluate_nn_model(vgg_model, cifar10_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_models(model, X_cifar10_scaled, y_cifar10):\n",
    "    # Machine Learning models\n",
    "\n",
    "    print(f\"\\nTraining {model.__class__.__name__} on CIFAR-10...\")\n",
    "    model.fit(X_cifar10_scaled, y_cifar10)  # Use scaled data\n",
    "\n",
    "\n",
    "def evaluate_ml_models(model, X_cifar10_scaled, y_cifar10):\n",
    "    y_pred = model.predict(X_cifar10_scaled)  # Use scaled data\n",
    "    accuracy = accuracy_score(y_cifar10, y_pred)\n",
    "    accuracy = 100 * accuracy\n",
    "    print(f\"{model.__class__.__name__} Accuracy on CIFAR-10 test set: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression on CIFAR-10...\n",
      "LogisticRegression Accuracy on CIFAR-10 test set: 28.01%\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(max_iter=3000, n_jobs=-1)\n",
    "train_ml_models(logistic_model, X_cifar10, y_cifar10)\n",
    "evaluate_ml_models(logistic_model, X_cifar10_test, y_cifar10_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForestClassifier on CIFAR-10...\n",
      "RandomForestClassifier Accuracy on CIFAR-10 test set: 41.64%\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(n_jobs=-1)\n",
    "train_ml_models(random_forest_model, X_cifar10, y_cifar10)\n",
    "evaluate_ml_models(random_forest_model, X_cifar10_test, y_cifar10_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBClassifier on CIFAR-10...\n",
      "XGBClassifier Accuracy on CIFAR-10 test set: 47.10%\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(n_jobs=-1)\n",
    "train_ml_models(xgb_model, X_cifar10, y_cifar10)\n",
    "evaluate_ml_models(xgb_model, X_cifar10_test, y_cifar10_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
