{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains the code to run the baseline experiments.\n",
    "\n",
    "More specifically, we are investigating the performance of basic models on the CIFAR-10 and CIFAR-10H datasets. The tasks for these datasets are multi-class classification.\n",
    "\n",
    "The basic models include:\n",
    "    * ResNet-50\n",
    "    * VGG-16\n",
    "    * Logistic Regression\n",
    "    * Random Forest\n",
    "    * XGBoost\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10H dataset and return a Dataset\n",
    "def load_cifar10h() -> Dataset:\n",
    "    cifar10h_probs_path = \"../data/cifar-10h/cifar10h-probs.npy\"\n",
    "    if not os.path.exists(cifar10h_probs_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Soft labels not found at {cifar10h_probs_path}. Please ensure the CIFAR-10H data is downloaded.\"\n",
    "        )\n",
    "\n",
    "    cifar10h_probs = np.load(cifar10h_probs_path).astype(np.float32)\n",
    "    cifar10_test = datasets.CIFAR10(\n",
    "        root=\"../data/cifar-10\", train=False, download=True, transform=transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    class CIFAR10H(Dataset):\n",
    "        def __init__(self, cifar10_dataset: Dataset, soft_labels: np.ndarray):\n",
    "            self.cifar10_dataset = cifar10_dataset\n",
    "            self.soft_labels = soft_labels\n",
    "\n",
    "        def __len__(self) -> int:\n",
    "            return len(self.cifar10_dataset)\n",
    "\n",
    "        def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "            image, _ = self.cifar10_dataset[idx]\n",
    "            soft_label = torch.from_numpy(self.soft_labels[idx])\n",
    "            return image.float(), soft_label\n",
    "\n",
    "    cifar10h_dataset = CIFAR10H(cifar10_test, cifar10h_probs)\n",
    "    return cifar10h_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset and return train, validation, and test DataLoaders\n",
    "def load_cifar10() -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ConvertImageDtype(torch.float32),\n",
    "        ]\n",
    "    )\n",
    "    full_dataset = datasets.CIFAR10(root=\"../data/cifar-10\", train=True, download=True, transform=transform)\n",
    "\n",
    "    # This dataset will be used for testing and validation.\n",
    "    #   30% of the data will be used for validation, and 70% for testing.\n",
    "    test_size = int(0.7 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - test_size\n",
    "    test_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [test_size, val_size], generator=torch.Generator().manual_seed(229)\n",
    "    )\n",
    "\n",
    "    return test_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_data(cifar10h_dataset, cifar10_test_dataset):\n",
    "    # Prepare data for ML models\n",
    "    X_cifar10h = np.array([img.numpy().flatten() for img, _ in cifar10h_dataset])\n",
    "    y_cifar10h = np.array([np.argmax(label) for _, label in cifar10h_dataset])\n",
    "\n",
    "    X_cifar10_test = np.array([img.numpy().flatten() for img, _ in cifar10_test_dataset])\n",
    "    y_cifar10_test = np.array([label for _, label in cifar10_test_dataset])\n",
    "\n",
    "    # Scale the data for ML models\n",
    "    scaler = StandardScaler()\n",
    "    X_cifar10h_scaled = scaler.fit_transform(X_cifar10h)\n",
    "    X_cifar10_scaled_test = scaler.transform(X_cifar10_test)\n",
    "\n",
    "    return X_cifar10h_scaled, y_cifar10h, X_cifar10_scaled_test, y_cifar10_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CIFAR-10H dataset loaded with 10000 samples\n",
      "Files already downloaded and verified\n",
      "CIFAR-10 dataset loaded with 35000 test and 15000 validation samples\n"
     ]
    }
   ],
   "source": [
    "cifar10h_dataset = load_cifar10h()\n",
    "cifar10h_loader = DataLoader(cifar10h_dataset, batch_size=128, shuffle=True)\n",
    "print(f\"CIFAR-10H dataset loaded with {len(cifar10h_dataset)} samples\")\n",
    "\n",
    "cifar10_test_dataset, cifar10_val_dataset = load_cifar10()  # Changed variable name to reflect split\n",
    "cifar10_test_loader = DataLoader(cifar10_test_dataset, batch_size=128, shuffle=False)\n",
    "cifar10_val_loader = DataLoader(cifar10_val_dataset, batch_size=128, shuffle=False)\n",
    "print(\n",
    "    f\"CIFAR-10 dataset loaded with {len(cifar10_test_dataset)} test and {len(cifar10_val_dataset)} validation samples\"\n",
    ")\n",
    "X_cifar10h, y_cifar10h, X_cifar10_test, y_cifar10_test = get_ml_data(cifar10h_dataset, cifar10_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Training is done on the CIFAR-10H dataset. Evaluation is done on the CIFAR-10 train set, which we use as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    num_epochs: int,\n",
    ") -> nn.Module:\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                if len(labels.shape) > 1:  # For soft labels\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    _, labels = torch.max(labels, 1)\n",
    "                else:  # For hard labels\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Save model if validation accuracy improves\n",
    "        if accuracy > best_val_acc:\n",
    "            best_val_acc = accuracy\n",
    "            torch.save(model.state_dict(), f\"models/{model.__class__.__name__}_cifar10h.pth\")\n",
    "            print(f\"Saved model with improved validation accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(\n",
    "    model, cifar10h_loader: DataLoader, cifar10_val_loader: DataLoader, num_epochs: int = 20, lr: float = 0.001\n",
    ") -> list:\n",
    "    print(f\"\\nTraining {model.__class__.__name__} on CIFAR-10H...\")\n",
    "\n",
    "    # Adjust the final layer for CIFAR-10\n",
    "    if isinstance(model, models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 10)\n",
    "    elif isinstance(model, models.VGG):\n",
    "        num_ftrs = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=cifar10h_loader,\n",
    "        val_loader=cifar10_val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "    )\n",
    "    torch.save(model.state_dict(), f\"models/{model.__class__.__name__}_cifar10h.pth\")\n",
    "\n",
    "def evaluate_nn_model(model, cifar10_test_loader):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f\"models/{model.__class__.__name__}_cifar10h.pth\", weights_only=True)\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        for images, labels in cifar10_test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{model.__class__.__name__} Accuracy on CIFAR-10 test set: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet on CIFAR-10H...\n",
      "Using device: mps\n",
      "Epoch [1/20] Train Loss: 1.3566, Validation Loss: 1.7180, Accuracy: 58.77%\n",
      "Saved model with improved validation accuracy: 58.77%\n",
      "Epoch [2/20] Train Loss: 0.8915, Validation Loss: 0.8933, Accuracy: 69.05%\n",
      "Saved model with improved validation accuracy: 69.05%\n",
      "Epoch [3/20] Train Loss: 0.6604, Validation Loss: 0.8535, Accuracy: 71.59%\n",
      "Saved model with improved validation accuracy: 71.59%\n",
      "Epoch [4/20] Train Loss: 0.5384, Validation Loss: 1.1491, Accuracy: 64.92%\n",
      "Epoch [5/20] Train Loss: 0.4909, Validation Loss: 0.8586, Accuracy: 72.52%\n",
      "Saved model with improved validation accuracy: 72.52%\n",
      "Epoch [6/20] Train Loss: 0.3884, Validation Loss: 0.8214, Accuracy: 74.01%\n",
      "Saved model with improved validation accuracy: 74.01%\n",
      "Epoch [7/20] Train Loss: 0.3394, Validation Loss: 0.9465, Accuracy: 71.64%\n",
      "Epoch [8/20] Train Loss: 0.3005, Validation Loss: 0.8234, Accuracy: 75.04%\n",
      "Saved model with improved validation accuracy: 75.04%\n",
      "Epoch [9/20] Train Loss: 0.2856, Validation Loss: 0.8333, Accuracy: 74.33%\n",
      "Epoch [10/20] Train Loss: 0.2643, Validation Loss: 0.8898, Accuracy: 73.23%\n",
      "Epoch [11/20] Train Loss: 0.2661, Validation Loss: 0.8227, Accuracy: 75.20%\n",
      "Saved model with improved validation accuracy: 75.20%\n",
      "Epoch [12/20] Train Loss: 0.3050, Validation Loss: 0.8753, Accuracy: 73.48%\n",
      "Epoch [13/20] Train Loss: 0.3358, Validation Loss: 0.8418, Accuracy: 74.16%\n",
      "Epoch [14/20] Train Loss: 0.2815, Validation Loss: 0.8483, Accuracy: 74.01%\n",
      "Epoch [15/20] Train Loss: 0.2802, Validation Loss: 0.9463, Accuracy: 71.75%\n",
      "Epoch [16/20] Train Loss: 0.2468, Validation Loss: 0.8017, Accuracy: 75.61%\n",
      "Saved model with improved validation accuracy: 75.61%\n",
      "Epoch [17/20] Train Loss: 0.2591, Validation Loss: 0.8668, Accuracy: 73.76%\n",
      "Epoch [18/20] Train Loss: 0.2946, Validation Loss: 1.0064, Accuracy: 71.29%\n",
      "Epoch [19/20] Train Loss: 0.4387, Validation Loss: 1.3054, Accuracy: 62.39%\n",
      "Epoch [20/20] Train Loss: 0.5689, Validation Loss: 0.9446, Accuracy: 70.02%\n",
      "ResNet Accuracy on CIFAR-10 test set: 70.31%\n"
     ]
    }
   ],
   "source": [
    "resnet_model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "train_nn_model(resnet_model, cifar10h_loader, cifar10_val_loader, lr=0.01)\n",
    "evaluate_nn_model(resnet_model, cifar10_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training VGG on CIFAR-10H...\n",
      "Using device: mps\n",
      "Epoch [1/20] Train Loss: 2.2085, Validation Loss: 1.8863, Accuracy: 18.87%\n",
      "Saved model with improved validation accuracy: 18.87%\n",
      "Epoch [2/20] Train Loss: 1.7973, Validation Loss: 2.1571, Accuracy: 25.99%\n",
      "Saved model with improved validation accuracy: 25.99%\n",
      "Epoch [3/20] Train Loss: 1.8139, Validation Loss: 1.6829, Accuracy: 31.70%\n",
      "Saved model with improved validation accuracy: 31.70%\n",
      "Epoch [4/20] Train Loss: 1.6383, Validation Loss: 1.5933, Accuracy: 30.55%\n",
      "Epoch [5/20] Train Loss: 1.5082, Validation Loss: 1.5470, Accuracy: 36.31%\n",
      "Saved model with improved validation accuracy: 36.31%\n",
      "Epoch [6/20] Train Loss: 1.3558, Validation Loss: 1.2906, Accuracy: 47.25%\n",
      "Saved model with improved validation accuracy: 47.25%\n",
      "Epoch [7/20] Train Loss: 1.2409, Validation Loss: 1.3168, Accuracy: 49.29%\n",
      "Saved model with improved validation accuracy: 49.29%\n",
      "Epoch [8/20] Train Loss: 1.0533, Validation Loss: 1.0867, Accuracy: 60.81%\n",
      "Saved model with improved validation accuracy: 60.81%\n",
      "Epoch [9/20] Train Loss: 0.9193, Validation Loss: 1.0152, Accuracy: 65.57%\n",
      "Saved model with improved validation accuracy: 65.57%\n",
      "Epoch [10/20] Train Loss: 0.8094, Validation Loss: 1.1222, Accuracy: 61.96%\n",
      "Epoch [11/20] Train Loss: 0.7362, Validation Loss: 1.0474, Accuracy: 67.05%\n",
      "Saved model with improved validation accuracy: 67.05%\n",
      "Epoch [12/20] Train Loss: 0.6264, Validation Loss: 1.0029, Accuracy: 69.29%\n",
      "Saved model with improved validation accuracy: 69.29%\n",
      "Epoch [13/20] Train Loss: 0.5447, Validation Loss: 0.9324, Accuracy: 69.45%\n",
      "Saved model with improved validation accuracy: 69.45%\n",
      "Epoch [14/20] Train Loss: 0.5134, Validation Loss: 0.9432, Accuracy: 72.87%\n",
      "Saved model with improved validation accuracy: 72.87%\n",
      "Epoch [15/20] Train Loss: 0.4500, Validation Loss: 1.0804, Accuracy: 69.61%\n",
      "Epoch [16/20] Train Loss: 0.4198, Validation Loss: 0.9146, Accuracy: 71.85%\n",
      "Epoch [17/20] Train Loss: 0.3874, Validation Loss: 0.9018, Accuracy: 73.30%\n",
      "Saved model with improved validation accuracy: 73.30%\n",
      "Epoch [18/20] Train Loss: 0.3882, Validation Loss: 0.9499, Accuracy: 73.55%\n",
      "Saved model with improved validation accuracy: 73.55%\n",
      "Epoch [19/20] Train Loss: 0.3672, Validation Loss: 1.0014, Accuracy: 71.92%\n",
      "Epoch [20/20] Train Loss: 0.3409, Validation Loss: 0.9339, Accuracy: 73.71%\n",
      "Saved model with improved validation accuracy: 73.71%\n",
      "VGG Accuracy on CIFAR-10 test set: 74.29%\n"
     ]
    }
   ],
   "source": [
    "vgg_model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "train_nn_model(vgg_model, cifar10h_loader, cifar10_val_loader, lr=0.001)\n",
    "evaluate_nn_model(vgg_model, cifar10_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_models(model, X_cifar10h_scaled, y_cifar10h):\n",
    "    # Machine Learning models\n",
    "\n",
    "    print(f\"\\nTraining {model.__class__.__name__} on CIFAR-10H...\")\n",
    "    model.fit(X_cifar10h_scaled, y_cifar10h)  # Use scaled data\n",
    "\n",
    "\n",
    "def evaluate_ml_models(model, X_cifar10_scaled, y_cifar10):\n",
    "    y_pred = model.predict(X_cifar10_scaled)  # Use scaled data\n",
    "    accuracy = accuracy_score(y_cifar10, y_pred)\n",
    "    accuracy = 100 * accuracy\n",
    "    print(f\"{model.__class__.__name__} Accuracy on CIFAR-10 test set: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression on CIFAR-10H...\n",
      "LogisticRegression Accuracy on CIFAR-10 test set: 28.23%\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(max_iter=3000, n_jobs=-1)\n",
    "train_ml_models(logistic_model, X_cifar10h, y_cifar10h)\n",
    "evaluate_ml_models(logistic_model, X_cifar10_test, y_cifar10_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForestClassifier on CIFAR-10H...\n",
      "RandomForestClassifier Accuracy on CIFAR-10 test set: 41.49%\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(n_jobs=-1)\n",
    "train_ml_models(random_forest_model, X_cifar10h, y_cifar10h)\n",
    "evaluate_ml_models(random_forest_model, X_cifar10_test, y_cifar10_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBClassifier on CIFAR-10H...\n",
      "XGBClassifier Accuracy on CIFAR-10 test set: 47.35%\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(n_jobs=-1)\n",
    "train_ml_models(xgb_model, X_cifar10h, y_cifar10h)\n",
    "evaluate_ml_models(xgb_model, X_cifar10_test, y_cifar10_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
