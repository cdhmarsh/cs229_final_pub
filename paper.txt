# Key Results

## Ablation study
We test how the inclusion of soft labels helps performance, and whether including more gives us better results. We use the 10,000 sample CIFAR-10 test set, which has corresponding soft labels from CIFAR-10H. We range the proportion from 0% soft labels, to 25% soft labels (i.e. 75% hard labels), 50% soft labels, 75%, and 100% soft labels. We train ResNet34 using 9,000 images where they are split proportionally into soft and hard labels, and validate on 1,000 images. The results are below:

### Cross entropy loss vs proportion of soft labels
The validation cross entropy loss starts at around 0.92 when using only hard labels (0% soft labels). As we increase the proportion of soft labels to 25%, the validation loss decreases slightly to approximately 0.78. At 50% soft labels, we see a further small decrease to around 0.73. However, when moving to 75% soft labels, the validation loss decreases further to 0.7. Finally, with 100% soft labels, the validation loss remains elevated at around 0.7.

### Accuracy vs proportion of soft labels
0% is 76.20%
25% is 78.50%
50% is 78.70%
75% is 79.10%
100% is 79.30%