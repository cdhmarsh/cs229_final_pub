{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains the code to run experiments with artificial soft labels.\n",
    "\n",
    "The experiment is:\n",
    "    * Train a soft label predictor model on CIFAR-10H\n",
    "    * Generate artificial soft labels for CIFAR-10\n",
    "    * Train a model on CIFAR-10 with the artificial soft labels + CIFAR-10H\n",
    "    * Evaluate the model on CIFAR-10\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from generate_soft_labels import create_soft_label_dataset\n",
    "from soft_label_predictor import ImageHardToSoftLabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"Get the appropriate device (CUDA, MPS, or CPU).\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_experiment() -> Tuple[Dataset, Dataset, Dataset, Dataset]:\n",
    "    \"\"\"Load and split CIFAR-10 dataset into augment, train, test and validation sets.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    full_dataset = datasets.CIFAR10(root=\"../data/cifar-10\", train=True, download=True, transform=transform)\n",
    "    # Use test dataset for training, similar to CIFAR-10H experiment\n",
    "    train_dataset = datasets.CIFAR10(root=\"../data/cifar-10\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split full dataset for augmenting, testing, and validation\n",
    "    augment_size = int(0.7 * len(full_dataset))\n",
    "    val_size = (len(full_dataset) - augment_size) // 2\n",
    "    test_size = len(full_dataset) - augment_size - val_size\n",
    "\n",
    "    generator = torch.Generator().manual_seed(229)\n",
    "    augment_dataset, test_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [augment_size, test_size, val_size], generator=generator\n",
    "    )\n",
    "\n",
    "    return augment_dataset, train_dataset, test_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10LabelDataset(Dataset):\n",
    "    \"\"\"Dataset wrapper that handles both hard and soft labels consistently.\"\"\"\n",
    "    def __init__(self, dataset: Dataset, soft_labels: Optional[np.ndarray] = None):\n",
    "        self.dataset = dataset\n",
    "        self.soft_labels = soft_labels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        image, label = self.dataset[idx]\n",
    "        if self.soft_labels is None:\n",
    "            # Convert hard labels to one-hot\n",
    "            label = F.one_hot(torch.tensor(label), num_classes=10).float()\n",
    "        else:\n",
    "            label = torch.tensor(self.soft_labels[idx])\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Training is done on the CIFAR-10H dataset. Evaluation is done on the CIFAR-10 train set, which we use as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    num_epochs: int = 20,\n",
    "    model_path: Optional[str] = None,\n",
    ") -> Tuple[nn.Module, Dict[str, List[float]]]:\n",
    "    \"\"\"Train a neural network model and save the best version based on validation accuracy.\"\"\"\n",
    "\n",
    "    # Adjust the final layer for CIFAR-10 and add dropout\n",
    "    if isinstance(model, models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.1),  # Add dropout before final layer\n",
    "            nn.Linear(num_ftrs, 10)\n",
    "        )\n",
    "    elif isinstance(model, models.VGG):\n",
    "        num_ftrs = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Sequential(\n",
    "            nn.Dropout(0.1),  # Add dropout before final layer\n",
    "            nn.Linear(num_ftrs, 10)\n",
    "        )\n",
    "        \n",
    "    print(f\"Training on {device}\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    print(f\"\\nTraining {model.__class__.__name__}...\")\n",
    "    \n",
    "    # Initialize history dictionary\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Handle soft labels for training accuracy\n",
    "            train_labels = labels\n",
    "            if len(labels.shape) > 1:\n",
    "                _, train_labels = torch.max(labels, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += train_labels.size(0)\n",
    "            correct_train += (predicted == train_labels).sum().item()\n",
    "            \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                if len(labels.shape) > 1:  # For soft labels\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    _, labels = torch.max(labels, 1)\n",
    "                else:  # For hard labels\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Store metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(accuracy)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "            f\"Train Loss: {train_loss:.4f}, \"\n",
    "            f\"Val Loss: {val_loss:.4f}, \"\n",
    "            f\"Train Acc: {train_acc:.2f}%, \"\n",
    "            f\"Val Acc: {accuracy:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Save model if validation accuracy improves\n",
    "        if model_path is not None and accuracy > best_val_acc:\n",
    "            best_val_acc = accuracy\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Saved model with improved validation accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, dataloader: DataLoader, device: torch.device) -> Dict:\n",
    "    \"\"\"Evaluate model performance with multiple metrics.\"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    total = correct = total_loss = total_cross_entropy = total_kl_div = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    all_pred_probs, all_true_probs = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            original_labels = labels.clone()\n",
    "            \n",
    "            if len(labels.shape) > 1:\n",
    "                _, labels = torch.max(labels, 1)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred_probs = F.softmax(outputs, dim=1)\n",
    "            log_probs = F.log_softmax(outputs, dim=1)\n",
    "            \n",
    "            # Handle soft vs hard labels\n",
    "            if len(original_labels.shape) > 1:\n",
    "                original_labels = original_labels.to(device)\n",
    "                cross_entropy = -(original_labels * log_probs).sum()\n",
    "                total_cross_entropy += cross_entropy.item()\n",
    "                kl_div = F.kl_div(log_probs, original_labels, reduction='sum')\n",
    "                all_true_probs.extend(original_labels.cpu().numpy())\n",
    "            else:\n",
    "                total_cross_entropy += loss.item()\n",
    "                true_probs = F.one_hot(labels, num_classes=outputs.size(1)).float()\n",
    "                kl_div = F.kl_div(log_probs, true_probs, reduction='sum')\n",
    "                all_true_probs.extend(true_probs.cpu().numpy())\n",
    "            \n",
    "            total_kl_div += kl_div.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_pred_probs.extend(pred_probs.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': correct / total,\n",
    "        'precision': precision_score(all_labels, all_preds, average='macro', zero_division=0),\n",
    "        'recall': recall_score(all_labels, all_preds, average='macro', zero_division=0),\n",
    "        'f1': f1_score(all_labels, all_preds, average='macro', zero_division=0),\n",
    "        'loss': total_loss / total,  # Per-sample loss\n",
    "        'cross_entropy': total_cross_entropy / total,  # Per-sample cross entropy\n",
    "        'kl_divergence': total_kl_div / total,  # Per-sample KL divergence\n",
    "        'confusion_matrix': confusion_matrix(all_labels, all_preds),\n",
    "        'true_labels': np.array(all_labels),\n",
    "        'predictions': np.array(all_preds),\n",
    "        'pred_probabilities': np.array(all_pred_probs),\n",
    "        'true_probabilities': np.array(all_true_probs)\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_proportion_experiment(\n",
    "    full_dataset: Dataset,\n",
    "    soft_label_model: nn.Module,\n",
    "    val_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    soft_proportions: List[float] = [0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "    num_epochs: int = 20,\n",
    ") -> Tuple[Dict, Dict]:\n",
    "    \"\"\"Run experiments with different proportions of soft vs hard labels.\"\"\"    \n",
    "    results = {}\n",
    "    histories = {}  # Store training histories\n",
    "\n",
    "    total_samples = len(full_dataset)\n",
    "    \n",
    "    for prop in soft_proportions:\n",
    "        print(f\"\\nRunning experiment with {int(prop*100)}% soft labels\")\n",
    "        model_path = f\"models/ResNet_cifar10h_soft_{int(prop*100)}percent.pth\"\n",
    "        \n",
    "        # Split dataset into soft and hard label portions\n",
    "        indices = torch.randperm(total_samples, generator=torch.Generator().manual_seed(229))\n",
    "        soft_size = int(total_samples * prop)\n",
    "        \n",
    "        soft_indices = indices[:soft_size]\n",
    "        hard_indices = indices[soft_size:]\n",
    "        \n",
    "        # Create datasets\n",
    "        if soft_size > 0:\n",
    "            soft_subset = Subset(full_dataset, soft_indices)\n",
    "            soft_loader = DataLoader(soft_subset, batch_size=128, shuffle=False)\n",
    "            soft_dataset = create_soft_label_dataset(soft_label_model, soft_loader, device)\n",
    "        \n",
    "        if len(hard_indices) > 0:\n",
    "            hard_subset = Subset(full_dataset, hard_indices)\n",
    "            hard_dataset = CIFAR10LabelDataset(hard_subset)\n",
    "        \n",
    "        # Combine datasets based on proportion\n",
    "        combined_dataset = (\n",
    "            hard_dataset if prop == 0.0\n",
    "            else soft_dataset if prop == 1.0\n",
    "            else ConcatDataset([hard_dataset, soft_dataset])\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(combined_dataset, batch_size=128, shuffle=True)\n",
    "        \n",
    "        # Train and evaluate model\n",
    "        model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        model, history = train_model(\n",
    "            model, train_loader, val_loader, num_epochs=num_epochs, model_path=model_path, device=device\n",
    "        )\n",
    "        histories[prop] = history\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # Collect metrics\n",
    "        results[prop] = {\n",
    "            **{f'train_{k}': v for k, v in evaluate_model(model, train_loader, device).items()},\n",
    "            **{f'val_{k}': v for k, v in evaluate_model(model, val_loader, device).items()},\n",
    "            **{f'test_{k}': v for k, v in evaluate_model(model, test_loader, device).items()}\n",
    "        }\n",
    "    \n",
    "    return results, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basic_metrics(results: Dict):\n",
    "    \"\"\"Plot basic metrics like accuracy, loss etc.\"\"\"\n",
    "    metrics = [\n",
    "        ('cross_entropy', 'Cross Entropy Loss'),\n",
    "        ('kl_divergence', 'KL Divergence'),\n",
    "        ('accuracy', 'Accuracy'),\n",
    "        ('precision', 'Precision'),\n",
    "        ('recall', 'Recall'),\n",
    "        ('f1', 'F1 Score')\n",
    "    ]\n",
    "\n",
    "    proportions = list(results.keys())\n",
    "    x_axis = [p*100 for p in proportions]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (metric, title) in enumerate(metrics):\n",
    "        train_metric = [results[p][f'train_{metric}'] * 100 for p in proportions]\n",
    "        val_metric = [results[p][f'val_{metric}'] * 100 for p in proportions]\n",
    "        test_metric = [results[p][f'test_{metric}'] * 100 for p in proportions]\n",
    "        \n",
    "        axes[i].plot(x_axis, train_metric, 'b-o', label='Training')\n",
    "        axes[i].plot(x_axis, val_metric, 'r-o', label='Validation')\n",
    "        axes[i].plot(x_axis, test_metric, 'g-o', label='Test')\n",
    "        axes[i].set_xlabel('Percentage of Soft Labels')\n",
    "        axes[i].set_ylabel(f'{title} (%)')\n",
    "        axes[i].set_title(f'{title} vs Proportion of Soft Labels')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/metrics.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrices(results: Dict):\n",
    "    \"\"\"Plot confusion matrices for different proportions of soft labels.\"\"\"\n",
    "    proportions = list(results.keys())\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, prop in enumerate(proportions):\n",
    "        cm = results[prop]['test_confusion_matrix']  # Use test set confusion matrix\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(cm_normalized, annot=True, fmt='.2f', ax=axes[i], cmap='Blues')\n",
    "        axes[i].set_title(f'Normalized Confusion Matrix ({int(prop*100)}% Soft Labels)')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('True')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/confusion_matrices.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_pr_curves(results: Dict):\n",
    "    \"\"\"Plot ROC and Precision-Recall curves.\"\"\"\n",
    "    proportions = list(results.keys())\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    for prop in proportions:\n",
    "        test_true = results[prop]['test_true_labels']\n",
    "        test_probs = results[prop]['test_pred_probabilities']\n",
    "        \n",
    "        # One-vs-Rest ROC curves\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        \n",
    "        # Convert to one-hot format\n",
    "        test_true_bin = np.eye(10)[test_true]\n",
    "        \n",
    "        for class_idx in range(10):\n",
    "            fpr[class_idx], tpr[class_idx], _ = roc_curve(\n",
    "                test_true_bin[:, class_idx], test_probs[:, class_idx])\n",
    "            roc_auc[class_idx] = auc(fpr[class_idx], tpr[class_idx])\n",
    "        \n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr_micro, tpr_micro, _ = roc_curve(test_true_bin.ravel(), test_probs.ravel())\n",
    "        roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "        \n",
    "        ax1.plot(fpr_micro, tpr_micro, \n",
    "                label=f'{int(prop*100)}% Soft Labels (AUC = {roc_auc_micro:.2f})')\n",
    "        \n",
    "        # PR curve\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        pr_auc = dict()\n",
    "        \n",
    "        for class_idx in range(10):\n",
    "            precision[class_idx], recall[class_idx], _ = precision_recall_curve(\n",
    "                test_true_bin[:, class_idx], test_probs[:, class_idx])\n",
    "            pr_auc[class_idx] = auc(recall[class_idx], precision[class_idx])\n",
    "        \n",
    "        # Compute micro-average PR curve\n",
    "        precision_micro, recall_micro, _ = precision_recall_curve(\n",
    "            test_true_bin.ravel(), test_probs.ravel())\n",
    "        pr_auc_micro = auc(recall_micro, precision_micro)\n",
    "        \n",
    "        ax2.plot(recall_micro, precision_micro,\n",
    "                label=f'{int(prop*100)}% Soft Labels (AUC = {pr_auc_micro:.2f})')\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], 'k--')\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.set_title('ROC Curves (Micro-averaged)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.set_xlabel('Recall')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.set_title('Precision-Recall Curves (Micro-averaged)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/roc_pr_curves.png')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_training_curves(histories: Dict[float, Dict[str, List[float]]]):\n",
    "    \"\"\"Plot training curves for different soft label proportions.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    for prop, history in histories.items():\n",
    "        label = f\"{int(prop*100)}% Soft Labels\"\n",
    "        epochs = range(1, len(history['train_loss']) + 1)\n",
    "        \n",
    "        # Loss curves\n",
    "        ax1.plot(epochs, history['train_loss'], '--', label=f'Train ({label})')\n",
    "        ax1.plot(epochs, history['val_loss'], '-', label=f'Val ({label})')\n",
    "        \n",
    "        # Accuracy curves\n",
    "        ax2.plot(epochs, history['train_acc'], '--', label=f'Train ({label})')\n",
    "        ax2.plot(epochs, history['val_acc'], '-', label=f'Val ({label})')\n",
    "    \n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/training_curves.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR-10 dataset loaded with 35000 augment, 7500 test, and 7500 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "cifar10_datasets = load_cifar10_experiment()\n",
    "cifar10_hard_augment_dataset, _, cifar10_hard_test_dataset, cifar10_hard_val_dataset = cifar10_datasets\n",
    "\n",
    "# Create data loaders\n",
    "cifar10_hard_test_loader = DataLoader(cifar10_hard_test_dataset, batch_size=128, shuffle=False)\n",
    "cifar10_hard_val_loader = DataLoader(cifar10_hard_val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(\n",
    "    f\"CIFAR-10 dataset loaded with \"\n",
    "    f\"{len(cifar10_hard_augment_dataset)} augment, \"\n",
    "    f\"{len(cifar10_hard_test_dataset)} test, and \"\n",
    "    f\"{len(cifar10_hard_val_dataset)} validation samples\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageHardToSoftLabelModel(\n",
       "  (image_encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_image): Linear(in_features=4096, out_features=128, bias=True)\n",
       "  (fc_label): Linear(in_features=10, out_features=128, bias=True)\n",
       "  (fc_output): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (9): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare soft label model\n",
    "device = get_device()\n",
    "soft_label_model = ImageHardToSoftLabelModel().to(device)\n",
    "soft_label_model.load_state_dict(torch.load(\"models/soft_label_model.pt\", weights_only=True))\n",
    "soft_label_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment with 100% soft labels\n",
      "Training on cuda\n",
      "\n",
      "Training ResNet...\n",
      "Epoch [1/50] Train Loss: 1.1978, Val Loss: 0.9568, Train Acc: 61.49%, Val Acc: 67.68%\n",
      "Saved model with improved validation accuracy: 67.68%\n",
      "Epoch [2/50] Train Loss: 0.8616, Val Loss: 0.9631, Train Acc: 75.45%, Val Acc: 67.67%\n",
      "Epoch [3/50] Train Loss: 0.7279, Val Loss: 0.8315, Train Acc: 80.74%, Val Acc: 71.52%\n",
      "Saved model with improved validation accuracy: 71.52%\n",
      "Epoch [4/50] Train Loss: 0.6236, Val Loss: 0.9029, Train Acc: 85.18%, Val Acc: 70.27%\n",
      "Epoch [5/50] Train Loss: 0.5416, Val Loss: 0.8497, Train Acc: 88.55%, Val Acc: 73.05%\n",
      "Saved model with improved validation accuracy: 73.05%\n",
      "Epoch [6/50] Train Loss: 0.4820, Val Loss: 0.8096, Train Acc: 91.05%, Val Acc: 74.32%\n",
      "Saved model with improved validation accuracy: 74.32%\n",
      "Epoch [7/50] Train Loss: 0.4408, Val Loss: 0.8746, Train Acc: 92.90%, Val Acc: 72.73%\n",
      "Epoch [8/50] Train Loss: 0.4049, Val Loss: 0.8174, Train Acc: 94.55%, Val Acc: 75.43%\n",
      "Saved model with improved validation accuracy: 75.43%\n",
      "Epoch [9/50] Train Loss: 0.3838, Val Loss: 0.8596, Train Acc: 95.42%, Val Acc: 75.15%\n",
      "Epoch [10/50] Train Loss: 0.3660, Val Loss: 0.7597, Train Acc: 96.21%, Val Acc: 77.40%\n",
      "Saved model with improved validation accuracy: 77.40%\n",
      "Epoch [11/50] Train Loss: 0.3558, Val Loss: 0.8330, Train Acc: 96.62%, Val Acc: 76.12%\n",
      "Epoch [12/50] Train Loss: 0.3475, Val Loss: 0.8640, Train Acc: 96.96%, Val Acc: 75.09%\n",
      "Epoch [13/50] Train Loss: 0.3402, Val Loss: 0.8451, Train Acc: 97.29%, Val Acc: 75.65%\n",
      "Epoch [14/50] Train Loss: 0.3289, Val Loss: 0.8169, Train Acc: 97.69%, Val Acc: 76.12%\n",
      "Epoch [15/50] Train Loss: 0.3181, Val Loss: 0.8362, Train Acc: 98.13%, Val Acc: 75.71%\n",
      "Epoch [16/50] Train Loss: 0.3249, Val Loss: 0.8064, Train Acc: 97.85%, Val Acc: 76.96%\n",
      "Epoch [17/50] Train Loss: 0.3305, Val Loss: 0.8409, Train Acc: 97.59%, Val Acc: 74.97%\n",
      "Epoch [18/50] Train Loss: 0.3244, Val Loss: 0.8452, Train Acc: 97.87%, Val Acc: 75.95%\n",
      "Epoch [19/50] Train Loss: 0.3112, Val Loss: 0.8394, Train Acc: 98.45%, Val Acc: 76.21%\n",
      "Epoch [20/50] Train Loss: 0.3700, Val Loss: 0.8418, Train Acc: 96.18%, Val Acc: 75.23%\n",
      "Epoch [21/50] Train Loss: 0.3161, Val Loss: 0.7946, Train Acc: 98.26%, Val Acc: 76.47%\n",
      "Epoch [22/50] Train Loss: 0.2963, Val Loss: 0.7721, Train Acc: 99.04%, Val Acc: 78.23%\n",
      "Saved model with improved validation accuracy: 78.23%\n",
      "Epoch [23/50] Train Loss: 0.2932, Val Loss: 0.9231, Train Acc: 99.14%, Val Acc: 74.69%\n",
      "Epoch [24/50] Train Loss: 0.3056, Val Loss: 0.8966, Train Acc: 98.62%, Val Acc: 74.40%\n",
      "Epoch [25/50] Train Loss: 0.3214, Val Loss: 1.0321, Train Acc: 97.93%, Val Acc: 72.29%\n",
      "Epoch [26/50] Train Loss: 0.3155, Val Loss: 0.8657, Train Acc: 98.27%, Val Acc: 75.31%\n",
      "Epoch [27/50] Train Loss: 0.3207, Val Loss: 0.8309, Train Acc: 98.01%, Val Acc: 76.27%\n",
      "Epoch [28/50] Train Loss: 0.2976, Val Loss: 0.8139, Train Acc: 98.93%, Val Acc: 76.84%\n",
      "Epoch [29/50] Train Loss: 0.2939, Val Loss: 0.8667, Train Acc: 99.05%, Val Acc: 76.03%\n",
      "Epoch [30/50] Train Loss: 0.2976, Val Loss: 0.9010, Train Acc: 98.92%, Val Acc: 75.07%\n",
      "Epoch [31/50] Train Loss: 0.3034, Val Loss: 0.8778, Train Acc: 98.71%, Val Acc: 75.79%\n",
      "Epoch [32/50] Train Loss: 0.3038, Val Loss: 0.8630, Train Acc: 98.67%, Val Acc: 76.59%\n",
      "Epoch [33/50] Train Loss: 0.2955, Val Loss: 0.8786, Train Acc: 99.00%, Val Acc: 76.17%\n",
      "Epoch [34/50] Train Loss: 0.2989, Val Loss: 0.8805, Train Acc: 98.89%, Val Acc: 76.23%\n",
      "Epoch [35/50] Train Loss: 0.2987, Val Loss: 0.8628, Train Acc: 98.83%, Val Acc: 76.88%\n",
      "Epoch [36/50] Train Loss: 0.2886, Val Loss: 0.8801, Train Acc: 99.27%, Val Acc: 75.77%\n",
      "Epoch [37/50] Train Loss: 0.3006, Val Loss: 0.9084, Train Acc: 98.83%, Val Acc: 74.97%\n",
      "Epoch [38/50] Train Loss: 0.2951, Val Loss: 0.8693, Train Acc: 99.01%, Val Acc: 76.00%\n",
      "Epoch [39/50] Train Loss: 0.3649, Val Loss: 1.0517, Train Acc: 96.59%, Val Acc: 67.41%\n",
      "Epoch [40/50] Train Loss: 0.3797, Val Loss: 0.8529, Train Acc: 95.70%, Val Acc: 75.81%\n",
      "Epoch [41/50] Train Loss: 0.2861, Val Loss: 0.8099, Train Acc: 99.39%, Val Acc: 77.69%\n",
      "Epoch [42/50] Train Loss: 0.2870, Val Loss: 0.9041, Train Acc: 99.40%, Val Acc: 75.80%\n",
      "Epoch [43/50] Train Loss: 0.2809, Val Loss: 0.8646, Train Acc: 99.59%, Val Acc: 77.36%\n",
      "Epoch [44/50] Train Loss: 0.2782, Val Loss: 0.8715, Train Acc: 99.67%, Val Acc: 76.91%\n",
      "Epoch [45/50] Train Loss: 0.2793, Val Loss: 0.8978, Train Acc: 99.62%, Val Acc: 75.85%\n",
      "Epoch [46/50] Train Loss: 0.2852, Val Loss: 0.8997, Train Acc: 99.37%, Val Acc: 75.44%\n",
      "Epoch [47/50] Train Loss: 0.2937, Val Loss: 1.1341, Train Acc: 99.06%, Val Acc: 69.48%\n",
      "Epoch [48/50] Train Loss: 0.3025, Val Loss: 0.8546, Train Acc: 98.70%, Val Acc: 77.20%\n",
      "Epoch [49/50] Train Loss: 0.2841, Val Loss: 0.9100, Train Acc: 99.48%, Val Acc: 75.63%\n",
      "Epoch [50/50] Train Loss: 0.2895, Val Loss: 0.8917, Train Acc: 99.25%, Val Acc: 76.32%\n",
      "\n",
      "Running experiment with 75% soft labels\n",
      "Training on cuda\n",
      "\n",
      "Training ResNet...\n",
      "Epoch [1/50] Train Loss: 1.1876, Val Loss: 0.9209, Train Acc: 61.19%, Val Acc: 67.49%\n",
      "Saved model with improved validation accuracy: 67.49%\n",
      "Epoch [2/50] Train Loss: 0.8511, Val Loss: 0.8371, Train Acc: 74.65%, Val Acc: 71.47%\n",
      "Saved model with improved validation accuracy: 71.47%\n",
      "Epoch [3/50] Train Loss: 0.7288, Val Loss: 0.8421, Train Acc: 79.23%, Val Acc: 71.83%\n",
      "Saved model with improved validation accuracy: 71.83%\n",
      "Epoch [4/50] Train Loss: 0.6420, Val Loss: 0.7740, Train Acc: 82.69%, Val Acc: 73.92%\n",
      "Saved model with improved validation accuracy: 73.92%\n",
      "Epoch [5/50] Train Loss: 0.5720, Val Loss: 0.6887, Train Acc: 85.83%, Val Acc: 76.83%\n",
      "Saved model with improved validation accuracy: 76.83%\n",
      "Epoch [6/50] Train Loss: 0.5283, Val Loss: 0.7255, Train Acc: 87.65%, Val Acc: 75.91%\n",
      "Epoch [7/50] Train Loss: 0.4908, Val Loss: 0.7799, Train Acc: 89.21%, Val Acc: 75.11%\n",
      "Epoch [8/50] Train Loss: 0.4538, Val Loss: 0.9135, Train Acc: 90.93%, Val Acc: 72.32%\n",
      "Epoch [9/50] Train Loss: 0.4407, Val Loss: 0.7543, Train Acc: 91.37%, Val Acc: 76.28%\n",
      "Epoch [10/50] Train Loss: 0.4123, Val Loss: 0.7283, Train Acc: 92.67%, Val Acc: 77.04%\n",
      "Saved model with improved validation accuracy: 77.04%\n",
      "Epoch [11/50] Train Loss: 0.3977, Val Loss: 0.6704, Train Acc: 93.19%, Val Acc: 78.31%\n",
      "Saved model with improved validation accuracy: 78.31%\n",
      "Epoch [12/50] Train Loss: 0.3796, Val Loss: 0.7155, Train Acc: 93.97%, Val Acc: 77.29%\n",
      "Epoch [13/50] Train Loss: 0.3791, Val Loss: 0.7908, Train Acc: 93.95%, Val Acc: 75.99%\n",
      "Epoch [14/50] Train Loss: 0.3784, Val Loss: 0.7095, Train Acc: 94.04%, Val Acc: 78.21%\n",
      "Epoch [15/50] Train Loss: 0.3578, Val Loss: 0.7696, Train Acc: 94.80%, Val Acc: 76.04%\n",
      "Epoch [16/50] Train Loss: 0.3929, Val Loss: 0.6839, Train Acc: 93.51%, Val Acc: 79.43%\n",
      "Saved model with improved validation accuracy: 79.43%\n",
      "Epoch [17/50] Train Loss: 0.3421, Val Loss: 0.7384, Train Acc: 95.43%, Val Acc: 77.64%\n",
      "Epoch [18/50] Train Loss: 0.3349, Val Loss: 0.7274, Train Acc: 95.62%, Val Acc: 77.75%\n",
      "Epoch [19/50] Train Loss: 0.3304, Val Loss: 0.7185, Train Acc: 95.93%, Val Acc: 78.81%\n",
      "Epoch [20/50] Train Loss: 0.3314, Val Loss: 0.6958, Train Acc: 95.80%, Val Acc: 78.85%\n",
      "Epoch [21/50] Train Loss: 0.3175, Val Loss: 0.7209, Train Acc: 96.29%, Val Acc: 78.29%\n",
      "Epoch [22/50] Train Loss: 0.3234, Val Loss: 0.7488, Train Acc: 95.97%, Val Acc: 77.68%\n",
      "Epoch [23/50] Train Loss: 0.3241, Val Loss: 0.7179, Train Acc: 96.15%, Val Acc: 78.51%\n",
      "Epoch [24/50] Train Loss: 0.3112, Val Loss: 0.7432, Train Acc: 96.63%, Val Acc: 77.97%\n",
      "Epoch [25/50] Train Loss: 0.3134, Val Loss: 0.7756, Train Acc: 96.45%, Val Acc: 77.43%\n",
      "Epoch [26/50] Train Loss: 0.3071, Val Loss: 0.7536, Train Acc: 96.75%, Val Acc: 77.95%\n",
      "Epoch [27/50] Train Loss: 0.3110, Val Loss: 0.7359, Train Acc: 96.58%, Val Acc: 78.23%\n",
      "Epoch [28/50] Train Loss: 0.3038, Val Loss: 0.7144, Train Acc: 96.92%, Val Acc: 79.23%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run experiments\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results, histories \u001b[38;5;241m=\u001b[39m \u001b[43mrun_proportion_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcifar10_hard_augment_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoft_label_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoft_label_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcifar10_hard_val_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcifar10_hard_test_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoft_proportions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 48\u001b[0m, in \u001b[0;36mrun_proportion_experiment\u001b[0;34m(full_dataset, soft_label_model, val_loader, test_loader, device, soft_proportions, num_epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Train and evaluate model\u001b[39;00m\n\u001b[1;32m     47\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet34(weights\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mResNet34_Weights\u001b[38;5;241m.\u001b[39mDEFAULT)\n\u001b[0;32m---> 48\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m histories[prop] \u001b[38;5;241m=\u001b[39m history\n\u001b[1;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "Cell \u001b[0;32mIn[5], line 61\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, device, num_epochs, model_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m     _, train_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(labels, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     60\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 61\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     64\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/envs/cs229_project/lib/python3.9/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/cs229_project/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/cs229_project/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run experiments\n",
    "results, histories = run_proportion_experiment(\n",
    "    full_dataset=cifar10_hard_augment_dataset,\n",
    "    soft_label_model=soft_label_model,\n",
    "    val_loader=cifar10_hard_val_loader,\n",
    "    test_loader=cifar10_hard_test_loader,\n",
    "    soft_proportions=[1.0, 0.75, 0.5, 0.25, 0.0],\n",
    "    num_epochs=50,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "df = pd.DataFrame(results).T * 100\n",
    "df.index = [f\"{idx:.0f}%\" for idx in df.index * 100]\n",
    "print(\"\\nResults by Soft Label Percentage:\")\n",
    "print(\"================================\")\n",
    "df[['train_accuracy', 'val_accuracy', 'test_accuracy', 'train_loss', 'val_loss', 'train_cross_entropy', 'val_cross_entropy', 'train_kl_divergence', 'val_kl_divergence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_basic_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_pr_curves(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
